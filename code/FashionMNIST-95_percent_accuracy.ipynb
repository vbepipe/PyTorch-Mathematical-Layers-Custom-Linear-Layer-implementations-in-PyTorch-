{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from typing import Tuple, Dict, Any, Optional, List\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
        "from torchvision import datasets, transforms\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "import random\n",
        "import time\n",
        "from datetime import datetime\n",
        "import copy\n",
        "\n",
        "# ============================================================================\n",
        "# GPU DEVICE SETUP FOR T4\n",
        "# ============================================================================\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "if device.type == 'cuda':\n",
        "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "\n",
        "def print_gpu_utilization():\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"GPU Memory Used: {torch.cuda.memory_allocated(0) / 1024**3:.1f} GB\")\n",
        "        print(f\"GPU Memory Cached: {torch.cuda.memory_reserved(0) / 1024**3:.1f} GB\")\n",
        "\n",
        "# ============================================================================\n",
        "# SOTA CONFIGURATION CONSTANTS - OPTIMIZED FOR T4 GPU\n",
        "# ============================================================================\n",
        "\n",
        "DATASET_NAMES = ['FashionMNIST']\n",
        "HIDDEN_DIM: int = 2048 #512\n",
        "LEARNING_RATE: float = 1e-3\n",
        "weight_decay_ = 1e-4\n",
        "DROPOUT_RATE: float = 0.4\n",
        "EPOCHS_PER_DATASET: int = 100\n",
        "BATCH_SIZE: int = 1024 #128  # Optimized for T4 GPU memory\n",
        "ENSEMBLE_SIZE: int = 3\n",
        "\n",
        "# ============================================================================\n",
        "# ENHANCED DATA AUGMENTATION\n",
        "# ============================================================================\n",
        "\n",
        "class MultiAugmentDataset(Dataset):\n",
        "    \"\"\"Enhanced dataset with multiple augmentations\"\"\"\n",
        "    def __init__(self, base_dataset, num_augments=2):\n",
        "        self.base = base_dataset\n",
        "        self.num_augments = num_augments\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.base) * self.num_augments\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        base_idx = idx // self.num_augments\n",
        "        return self.base[base_idx]\n",
        "\n",
        "class MixUp(object):\n",
        "    \"\"\"MixUp data augmentation\"\"\"\n",
        "    def __init__(self, alpha=0.2):\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def __call__(self, x, y):\n",
        "        if self.alpha > 0:\n",
        "            lam = np.random.beta(self.alpha, self.alpha)\n",
        "        else:\n",
        "            lam = 1\n",
        "\n",
        "        batch_size = x.size(0)\n",
        "        index = torch.randperm(batch_size).to(device)\n",
        "\n",
        "        mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "        y_a, y_b = y, y[index]\n",
        "        return mixed_x, y_a, y_b, lam\n",
        "\n",
        "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
        "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
        "\n",
        "def get_sota_data_loaders(dataset_name: str, batch_size: int) -> Tuple[DataLoader, DataLoader, int, int]:\n",
        "    \"\"\"SOTA data loading with advanced augmentation\"\"\"\n",
        "\n",
        "    if dataset_name == 'FashionMNIST':\n",
        "        transform_train = transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.RandomRotation(15),\n",
        "            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
        "            transforms.RandomResizedCrop(28, scale=(0.8, 1.0)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5,), (0.5,)),\n",
        "            transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3)),\n",
        "        ])\n",
        "\n",
        "        transform_test = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5,), (0.5,))\n",
        "        ])\n",
        "\n",
        "        train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform_train)\n",
        "        test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform_test)\n",
        "        n_classes = 10\n",
        "        n_channels = 1\n",
        "        img_size = 28\n",
        "\n",
        "    enhanced_train = MultiAugmentDataset(train_dataset, 2)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        enhanced_train,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "        prefetch_factor=2,\n",
        "        persistent_workers=True\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size * 2,\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        drop_last=False,\n",
        "        prefetch_factor=2,\n",
        "        persistent_workers=True\n",
        "    )\n",
        "\n",
        "    input_dim = (n_channels, img_size, img_size)\n",
        "    return train_loader, test_loader, input_dim, n_classes\n",
        "\n",
        "# ============================================================================\n",
        "# SOTA ARCHITECTURE COMPONENTS\n",
        "# ============================================================================\n",
        "\n",
        "class SEBlock(nn.Module):\n",
        "    \"\"\"Squeeze-and-Excitation Block\"\"\"\n",
        "    def __init__(self, channel, reduction=16):\n",
        "        super(SEBlock, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channel, channel // reduction, bias=False),\n",
        "            nn.SiLU(inplace=True),\n",
        "            nn.Linear(channel // reduction, channel, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        y = self.avg_pool(x).view(b, c)\n",
        "        y = self.fc(y).view(b, c, 1, 1)\n",
        "        return x * y.expand_as(x)\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    \"\"\"Advanced Residual Block with SE attention\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, stride=1, use_se=True):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, 1, stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "        self.se = SEBlock(out_channels) if use_se else None\n",
        "        self.dropout = nn.Dropout2d(0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = F.silu(self.bn1(self.conv1(x)))\n",
        "        out = self.dropout(out)\n",
        "        out = self.bn2(self.conv2(out))\n",
        "\n",
        "        if self.se:\n",
        "            out = self.se(out)\n",
        "\n",
        "        out += self.shortcut(residual)\n",
        "        out = F.silu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class MultiScaleBlock(nn.Module):\n",
        "    \"\"\"Multi-scale feature extraction\"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(MultiScaleBlock, self).__init__()\n",
        "\n",
        "        self.branch1 = nn.Conv2d(in_channels, out_channels//4, 1, bias=False)\n",
        "        self.branch2 = nn.Conv2d(in_channels, out_channels//4, 3, padding=1, bias=False)\n",
        "        self.branch3 = nn.Conv2d(in_channels, out_channels//4, 5, padding=2, bias=False)\n",
        "        self.branch4 = nn.Sequential(\n",
        "            nn.MaxPool2d(3, stride=1, padding=1),\n",
        "            nn.Conv2d(in_channels, out_channels//4, 1, bias=False)\n",
        "        )\n",
        "\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch1 = self.branch1(x)\n",
        "        branch2 = self.branch2(x)\n",
        "        branch3 = self.branch3(x)\n",
        "        branch4 = self.branch4(x)\n",
        "\n",
        "        out = torch.cat([branch1, branch2, branch3, branch4], 1)\n",
        "        return F.silu(self.bn(out))\n",
        "\n",
        "# ============================================================================\n",
        "# SOTA NEURAL NETWORK ARCHITECTURE\n",
        "# ============================================================================\n",
        "\n",
        "class SOTAFashionNet(nn.Module):\n",
        "    \"\"\"State-of-the-Art Architecture for FashionMNIST\"\"\"\n",
        "\n",
        "    def __init__(self, input_dim: tuple, hidden_dim: int, output_dim: int, dropout_rate: float = 0.4):\n",
        "        super(SOTAFashionNet, self).__init__()\n",
        "\n",
        "        channels, height, width = input_dim\n",
        "\n",
        "        self.initial_conv = nn.Sequential(\n",
        "            nn.Conv2d(channels, 32, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.SiLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.multiscale1 = MultiScaleBlock(32, 64)\n",
        "\n",
        "        self.res_block1 = ResidualBlock(64, 64)\n",
        "        self.res_block2 = ResidualBlock(64, 128, stride=2)\n",
        "        self.res_block3 = ResidualBlock(128, 128)\n",
        "        self.res_block4 = ResidualBlock(128, 256, stride=2)\n",
        "        self.res_block5 = ResidualBlock(256, 256)\n",
        "        self.res_block6 = ResidualBlock(256, 512, stride=2)\n",
        "\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512, hidden_dim),\n",
        "            nn.SiLU(inplace=True),\n",
        "            nn.Dropout(dropout_rate),\n",
        "\n",
        "            nn.Linear(hidden_dim, hidden_dim//2),\n",
        "            nn.SiLU(inplace=True),\n",
        "            nn.Dropout(dropout_rate//2),\n",
        "\n",
        "            nn.Linear(hidden_dim//2, hidden_dim//4),\n",
        "            nn.SiLU(inplace=True),\n",
        "            nn.Dropout(dropout_rate//4),\n",
        "\n",
        "            nn.Linear(hidden_dim//4, output_dim)\n",
        "        )\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        \"\"\"Advanced weight initialization\"\"\"\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_normal_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.initial_conv(x)\n",
        "        x = self.multiscale1(x)\n",
        "\n",
        "        x = self.res_block1(x)\n",
        "        x = self.res_block2(x)\n",
        "        x = self.res_block3(x)\n",
        "        x = self.res_block4(x)\n",
        "        x = self.res_block5(x)\n",
        "        x = self.res_block6(x)\n",
        "\n",
        "        x = self.global_avg_pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# ============================================================================\n",
        "# SOTA TRAINING WITH T4 GPU OPTIMIZATION\n",
        "# ============================================================================\n",
        "\n",
        "def train_sota_model(model: nn.Module, train_loader: DataLoader, criterion: nn.Module,\n",
        "                    test_loader: DataLoader, optimizer: optim.Optimizer, scheduler,\n",
        "                    num_epochs: int = 100, verbose: bool = True) -> float:\n",
        "\n",
        "    model = model.to(device)\n",
        "    scaler = GradScaler()  # Mixed precision training\n",
        "    mixup = MixUp(alpha=0.2)\n",
        "    best_accuracy = 0.0\n",
        "    patience_counter = 0\n",
        "    max_patience = 20\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "\n",
        "        for batch_x, batch_y in train_loader:\n",
        "            # Move data to GPU\n",
        "            batch_x = batch_x.to(device, non_blocking=True)\n",
        "            batch_y = batch_y.to(device, non_blocking=True)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Mixed precision training\n",
        "            with autocast():\n",
        "                if epoch > 20 and np.random.random() < 0.3:\n",
        "                    mixed_x, y_a, y_b, lam = mixup(batch_x, batch_y)\n",
        "                    outputs = model(mixed_x)\n",
        "                    loss = mixup_criterion(criterion, outputs, y_a, y_b, lam)\n",
        "                else:\n",
        "                    outputs = model(batch_x)\n",
        "                    loss = criterion(outputs, batch_y)\n",
        "\n",
        "            # Scaled backward pass\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Periodic GPU cache cleanup\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        scheduler.step()\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "\n",
        "        if epoch % 1 == 0:\n",
        "            test_loss, test_acc = evaluate_model(model, test_loader, criterion)\n",
        "\n",
        "            if verbose:\n",
        "                current_time = datetime.now().strftime(\"%B %d, %Y at %I:%M:%S %p\")\n",
        "                print(f\"Epoch {epoch}/{num_epochs}: Loss = {avg_loss:.4f} | \"\n",
        "                      f\"Test Acc = {test_acc:.2f}% | LR = {scheduler.get_last_lr()[0]:.6f} | Time: {current_time}\")\n",
        "                print_gpu_utilization()\n",
        "\n",
        "            if test_acc > best_accuracy:\n",
        "                best_accuracy = test_acc\n",
        "                patience_counter = 0\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "\n",
        "            if patience_counter >= max_patience//2:\n",
        "                print(f\"Early stopping at epoch {epoch}\")\n",
        "                break\n",
        "\n",
        "    return best_accuracy\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_model(model: nn.Module, test_loader: DataLoader, criterion: nn.Module) -> Tuple[float, float]:\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_x, batch_y in test_loader:\n",
        "        # Move data to GPU\n",
        "        batch_x = batch_x.to(device, non_blocking=True)\n",
        "        batch_y = batch_y.to(device, non_blocking=True)\n",
        "\n",
        "        with autocast():\n",
        "            outputs = model(batch_x)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        correct += (preds == batch_y).sum().item()\n",
        "        total += batch_y.size(0)\n",
        "\n",
        "    avg_loss = total_loss / len(test_loader)\n",
        "    accuracy = 100.0 * correct / total\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "# ============================================================================\n",
        "# ENSEMBLE TRAINING FOR T4 GPU\n",
        "# ============================================================================\n",
        "\n",
        "def train_ensemble_models(input_dim, hidden_dim, n_classes, train_loader, test_loader,\n",
        "                         ensemble_size=3) -> Tuple[List[nn.Module], List[float]]:\n",
        "    \"\"\"Train multiple models for ensembling - T4 GPU optimized\"\"\"\n",
        "\n",
        "    models = []\n",
        "    best_accuracies = []\n",
        "\n",
        "    for i in range(ensemble_size):\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Training Ensemble Model {i+1}/{ensemble_size}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        model_hidden = hidden_dim + (i * 64)\n",
        "        model = SOTAFashionNet(input_dim, model_hidden, n_classes, dropout_rate=DROPOUT_RATE + i*0.05)\n",
        "        model = model.to(device)\n",
        "\n",
        "        optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE * (0.9 + i*0.1),\n",
        "                               weight_decay=weight_decay_, betas=(0.9, 0.999), eps=1e-8)\n",
        "\n",
        "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS_PER_DATASET, eta_min=1e-6)\n",
        "        criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "\n",
        "        best_acc = train_sota_model(model, train_loader, criterion, test_loader, optimizer, scheduler,\n",
        "                                   num_epochs=EPOCHS_PER_DATASET)\n",
        "\n",
        "        models.append(model)\n",
        "        best_accuracies.append(best_acc)\n",
        "\n",
        "        print(f\"Model {i+1} Best Accuracy: {best_acc:.2f}%\")\n",
        "\n",
        "        # Clear GPU memory between models\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    return models, best_accuracies\n",
        "\n",
        "@torch.no_grad()\n",
        "def ensemble_predict(models: List[nn.Module], test_loader: DataLoader) -> float:\n",
        "    \"\"\"Make ensemble predictions\"\"\"\n",
        "    for model in models:\n",
        "        model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_x, batch_y in test_loader:\n",
        "        batch_x = batch_x.to(device, non_blocking=True)\n",
        "        batch_y = batch_y.to(device, non_blocking=True)\n",
        "\n",
        "        ensemble_outputs = []\n",
        "        for model in models:\n",
        "            with autocast():\n",
        "                outputs = model(batch_x)\n",
        "                ensemble_outputs.append(F.softmax(outputs, dim=1))\n",
        "\n",
        "        avg_outputs = torch.stack(ensemble_outputs).mean(0)\n",
        "        preds = avg_outputs.argmax(dim=1)\n",
        "\n",
        "        correct += (preds == batch_y).sum().item()\n",
        "        total += batch_y.size(0)\n",
        "\n",
        "    accuracy = 100.0 * correct / total\n",
        "    return accuracy\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN SOTA EXPERIMENT PIPELINE\n",
        "# ============================================================================\n",
        "\n",
        "def run_sota_experiments():\n",
        "    \"\"\"Run SOTA experiments - T4 GPU optimized\"\"\"\n",
        "\n",
        "    for dataset_name in DATASET_NAMES:\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"RUNNING SOTA EXPERIMENTS ON {dataset_name}\")\n",
        "        print(f\"TARGET: 95%+ ACCURACY (T4 GPU OPTIMIZED)\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        train_loader, test_loader, input_dim, n_classes = get_sota_data_loaders(dataset_name, BATCH_SIZE)\n",
        "        print(f\"Dataset: {dataset_name} | Input: {input_dim} | Classes: {n_classes}\")\n",
        "        print(f\"Train: {len(train_loader.dataset)} | Test: {len(test_loader.dataset)}\")\n",
        "        print_gpu_utilization()\n",
        "\n",
        "        models, individual_accuracies = train_ensemble_models(\n",
        "            input_dim, HIDDEN_DIM, n_classes, train_loader, test_loader, ENSEMBLE_SIZE\n",
        "        )\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(\"INDIVIDUAL MODEL RESULTS\")\n",
        "        print(f\"{'='*60}\")\n",
        "        for i, acc in enumerate(individual_accuracies):\n",
        "            print(f\"Model {i+1}: {acc:.2f}%\")\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(\"ENSEMBLE RESULTS\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        ensemble_acc = ensemble_predict(models, test_loader)\n",
        "        print(f\"Ensemble Accuracy: {ensemble_acc:.2f}%\")\n",
        "\n",
        "        final_accuracy = max(max(individual_accuracies), ensemble_acc)\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(\"FINAL SOTA RESULTS\")\n",
        "        print(f\"{'='*60}\")\n",
        "        print(f\"Best Individual Model: {max(individual_accuracies):.2f}%\")\n",
        "        print(f\"Ensemble Accuracy: {ensemble_acc:.2f}%\")\n",
        "        print(f\"FINAL BEST ACCURACY: {final_accuracy:.2f}%\")\n",
        "\n",
        "        if final_accuracy >= 97.0:\n",
        "            print(f\"🎉 EXCELLENT! {final_accuracy:.2f}% ≥ 97%\")\n",
        "        elif final_accuracy >= 95.0:\n",
        "            print(f\"✅ VERY GOOD! {final_accuracy:.2f}% ≥ 95%\")\n",
        "        elif final_accuracy >= 92.0:\n",
        "            print(f\"🟡 GOOD! {final_accuracy:.2f}% ≥ 92%\")\n",
        "        else:\n",
        "            print(f\"⚠️ NEEDS IMPROVEMENT: {final_accuracy:.2f}%\")\n",
        "\n",
        "def main():\n",
        "    SEED_ = 42\n",
        "    print(\"=\"*80)\n",
        "    print(\"T4 GPU-OPTIMIZED SOTA FASHIONMNIST IMPLEMENTATION\")\n",
        "    print(\"TARGET: 95%+ ACCURACY WITH ENSEMBLE\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"Device: {device}\")\n",
        "    print(f\"Ensemble Size: {ENSEMBLE_SIZE}\")\n",
        "    print(f\"Epochs per Model: {EPOCHS_PER_DATASET}\")\n",
        "    print(f\"Hidden Dim: {HIDDEN_DIM}\")\n",
        "    print(f\"Batch Size: {BATCH_SIZE}\")\n",
        "    print(f\"Mixed Precision: Enabled\")\n",
        "\n",
        "    torch.manual_seed(SEED_)\n",
        "    np.random.seed(SEED_)\n",
        "    random.seed(SEED_)\n",
        "\n",
        "    # Enable optimizations for T4 GPU\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "\n",
        "    run_sota_experiments()\n",
        "    print(\"\\n🎉 SOTA EXPERIMENTS COMPLETED!\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZER6W0E8a-5Y",
        "outputId": "24a4e2e6-ad3b-402d-a0fe-051e50548f3f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "GPU Name: Tesla T4\n",
            "GPU Memory: 14.7 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38fPGTQ8bB1T",
        "outputId": "e028ead7-691a-4dd3-ef82-90ae2508db97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "T4 GPU-OPTIMIZED SOTA FASHIONMNIST IMPLEMENTATION\n",
            "TARGET: 95%+ ACCURACY WITH ENSEMBLE\n",
            "================================================================================\n",
            "Device: cuda\n",
            "Ensemble Size: 3\n",
            "Epochs per Model: 100\n",
            "Hidden Dim: 2048\n",
            "Batch Size: 1024\n",
            "Mixed Precision: Enabled\n",
            "\n",
            "================================================================================\n",
            "RUNNING SOTA EXPERIMENTS ON FashionMNIST\n",
            "TARGET: 95%+ ACCURACY (T4 GPU OPTIMIZED)\n",
            "================================================================================\n",
            "Dataset: FashionMNIST | Input: (1, 28, 28) | Classes: 10\n",
            "Train: 120000 | Test: 10000\n",
            "GPU Memory Used: 0.0 GB\n",
            "GPU Memory Cached: 0.0 GB\n",
            "\n",
            "============================================================\n",
            "Training Ensemble Model 1/3\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4075558602.py:301: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Mixed precision training\n",
            "/tmp/ipython-input-4075558602.py:319: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-4075558602.py:377: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100: Loss = 1.1718 | Test Acc = 79.94% | LR = 0.000900 | Time: September 01, 2025 at 09:14:50 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 0.5 GB\n",
            "Epoch 2/100: Loss = 0.9198 | Test Acc = 86.24% | LR = 0.000899 | Time: September 01, 2025 at 09:16:10 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.7 GB\n",
            "Epoch 3/100: Loss = 0.8660 | Test Acc = 87.31% | LR = 0.000898 | Time: September 01, 2025 at 09:17:30 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.8 GB\n",
            "Epoch 4/100: Loss = 0.8295 | Test Acc = 88.74% | LR = 0.000896 | Time: September 01, 2025 at 09:18:49 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.8 GB\n",
            "Epoch 5/100: Loss = 0.8135 | Test Acc = 88.01% | LR = 0.000894 | Time: September 01, 2025 at 09:20:08 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.8 GB\n",
            "Epoch 6/100: Loss = 0.7935 | Test Acc = 89.75% | LR = 0.000892 | Time: September 01, 2025 at 09:21:28 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.8 GB\n",
            "Epoch 7/100: Loss = 0.7807 | Test Acc = 90.44% | LR = 0.000889 | Time: September 01, 2025 at 09:22:48 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.8 GB\n",
            "Epoch 8/100: Loss = 0.7684 | Test Acc = 91.04% | LR = 0.000886 | Time: September 01, 2025 at 09:24:08 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.8 GB\n",
            "Epoch 9/100: Loss = 0.7586 | Test Acc = 91.17% | LR = 0.000882 | Time: September 01, 2025 at 09:25:29 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.8 GB\n",
            "Epoch 10/100: Loss = 0.7489 | Test Acc = 91.75% | LR = 0.000878 | Time: September 01, 2025 at 09:26:50 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.8 GB\n",
            "Epoch 11/100: Loss = 0.7420 | Test Acc = 91.95% | LR = 0.000873 | Time: September 01, 2025 at 09:28:11 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.8 GB\n",
            "Epoch 12/100: Loss = 0.7362 | Test Acc = 91.55% | LR = 0.000868 | Time: September 01, 2025 at 09:29:32 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.8 GB\n",
            "Epoch 13/100: Loss = 0.7287 | Test Acc = 92.41% | LR = 0.000863 | Time: September 01, 2025 at 09:30:54 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.8 GB\n",
            "Epoch 14/100: Loss = 0.7235 | Test Acc = 91.62% | LR = 0.000857 | Time: September 01, 2025 at 09:32:14 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.8 GB\n",
            "Epoch 15/100: Loss = 0.7181 | Test Acc = 92.27% | LR = 0.000851 | Time: September 01, 2025 at 09:33:34 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.8 GB\n",
            "Epoch 16/100: Loss = 0.7166 | Test Acc = 92.95% | LR = 0.000844 | Time: September 01, 2025 at 09:34:54 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.8 GB\n",
            "Epoch 17/100: Loss = 0.7104 | Test Acc = 93.02% | LR = 0.000837 | Time: September 01, 2025 at 09:36:17 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.8 GB\n",
            "Epoch 18/100: Loss = 0.7038 | Test Acc = 92.17% | LR = 0.000830 | Time: September 01, 2025 at 09:37:38 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.8 GB\n",
            "Epoch 19/100: Loss = 0.6998 | Test Acc = 92.55% | LR = 0.000822 | Time: September 01, 2025 at 09:38:58 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.8 GB\n",
            "Epoch 20/100: Loss = 0.6965 | Test Acc = 93.23% | LR = 0.000814 | Time: September 01, 2025 at 09:40:18 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.8 GB\n",
            "Epoch 21/100: Loss = 0.8014 | Test Acc = 92.60% | LR = 0.000806 | Time: September 01, 2025 at 09:41:39 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.9 GB\n",
            "Epoch 22/100: Loss = 0.7899 | Test Acc = 92.92% | LR = 0.000797 | Time: September 01, 2025 at 09:42:59 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.8 GB\n",
            "Epoch 23/100: Loss = 0.7508 | Test Acc = 93.28% | LR = 0.000788 | Time: September 01, 2025 at 09:44:20 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.8 GB\n",
            "Epoch 24/100: Loss = 0.8045 | Test Acc = 93.33% | LR = 0.000778 | Time: September 01, 2025 at 09:45:40 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.8 GB\n",
            "Epoch 25/100: Loss = 0.7617 | Test Acc = 92.87% | LR = 0.000768 | Time: September 01, 2025 at 09:47:01 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.8 GB\n",
            "Epoch 26/100: Loss = 0.7829 | Test Acc = 93.52% | LR = 0.000758 | Time: September 01, 2025 at 09:48:21 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.8 GB\n",
            "Epoch 27/100: Loss = 0.7486 | Test Acc = 93.87% | LR = 0.000748 | Time: September 01, 2025 at 09:49:41 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.8 GB\n",
            "Epoch 28/100: Loss = 0.7319 | Test Acc = 93.75% | LR = 0.000737 | Time: September 01, 2025 at 09:51:00 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.8 GB\n",
            "Epoch 29/100: Loss = 0.7557 | Test Acc = 92.98% | LR = 0.000726 | Time: September 01, 2025 at 09:52:21 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.8 GB\n",
            "Epoch 30/100: Loss = 0.7463 | Test Acc = 93.56% | LR = 0.000715 | Time: September 01, 2025 at 09:53:41 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.9 GB\n",
            "Epoch 31/100: Loss = 0.7590 | Test Acc = 93.74% | LR = 0.000703 | Time: September 01, 2025 at 09:55:01 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.8 GB\n",
            "Epoch 32/100: Loss = 0.7156 | Test Acc = 94.05% | LR = 0.000691 | Time: September 01, 2025 at 09:56:22 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.9 GB\n",
            "Epoch 33/100: Loss = 0.7073 | Test Acc = 93.89% | LR = 0.000679 | Time: September 01, 2025 at 09:57:43 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.8 GB\n",
            "Epoch 34/100: Loss = 0.7322 | Test Acc = 93.76% | LR = 0.000667 | Time: September 01, 2025 at 09:59:03 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.8 GB\n",
            "Epoch 35/100: Loss = 0.7367 | Test Acc = 93.96% | LR = 0.000655 | Time: September 01, 2025 at 10:00:23 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.9 GB\n",
            "Epoch 36/100: Loss = 0.7674 | Test Acc = 94.13% | LR = 0.000642 | Time: September 01, 2025 at 10:01:43 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.9 GB\n",
            "Epoch 37/100: Loss = 0.7695 | Test Acc = 93.87% | LR = 0.000629 | Time: September 01, 2025 at 10:03:05 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.8 GB\n",
            "Epoch 38/100: Loss = 0.7194 | Test Acc = 94.08% | LR = 0.000616 | Time: September 01, 2025 at 10:04:25 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.8 GB\n",
            "Epoch 39/100: Loss = 0.7218 | Test Acc = 93.80% | LR = 0.000603 | Time: September 01, 2025 at 10:05:44 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.9 GB\n",
            "Epoch 40/100: Loss = 0.7309 | Test Acc = 94.41% | LR = 0.000589 | Time: September 01, 2025 at 10:07:03 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.9 GB\n",
            "Epoch 41/100: Loss = 0.7186 | Test Acc = 94.27% | LR = 0.000576 | Time: September 01, 2025 at 10:08:23 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.9 GB\n",
            "Epoch 42/100: Loss = 0.6982 | Test Acc = 94.09% | LR = 0.000562 | Time: September 01, 2025 at 10:09:45 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.8 GB\n",
            "Epoch 43/100: Loss = 0.7419 | Test Acc = 94.37% | LR = 0.000549 | Time: September 01, 2025 at 10:11:06 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.8 GB\n",
            "Epoch 44/100: Loss = 0.7277 | Test Acc = 94.76% | LR = 0.000535 | Time: September 01, 2025 at 10:12:27 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.8 GB\n",
            "Epoch 45/100: Loss = 0.7192 | Test Acc = 94.45% | LR = 0.000521 | Time: September 01, 2025 at 10:13:48 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.9 GB\n",
            "Epoch 46/100: Loss = 0.6998 | Test Acc = 94.57% | LR = 0.000507 | Time: September 01, 2025 at 10:15:11 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.8 GB\n",
            "Epoch 47/100: Loss = 0.7071 | Test Acc = 94.37% | LR = 0.000493 | Time: September 01, 2025 at 10:16:30 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.8 GB\n",
            "Epoch 48/100: Loss = 0.7257 | Test Acc = 94.61% | LR = 0.000479 | Time: September 01, 2025 at 10:17:50 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.9 GB\n",
            "Epoch 49/100: Loss = 0.7342 | Test Acc = 94.29% | LR = 0.000465 | Time: September 01, 2025 at 10:19:10 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.8 GB\n",
            "Epoch 50/100: Loss = 0.7274 | Test Acc = 94.50% | LR = 0.000451 | Time: September 01, 2025 at 10:20:30 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.9 GB\n",
            "Epoch 51/100: Loss = 0.6847 | Test Acc = 94.40% | LR = 0.000436 | Time: September 01, 2025 at 10:21:50 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.8 GB\n",
            "Epoch 52/100: Loss = 0.6973 | Test Acc = 94.42% | LR = 0.000422 | Time: September 01, 2025 at 10:23:11 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.9 GB\n",
            "Epoch 53/100: Loss = 0.7240 | Test Acc = 94.56% | LR = 0.000408 | Time: September 01, 2025 at 10:24:31 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.9 GB\n",
            "Epoch 54/100: Loss = 0.6975 | Test Acc = 94.75% | LR = 0.000394 | Time: September 01, 2025 at 10:25:52 AM\n",
            "GPU Memory Used: 0.2 GB\n",
            "GPU Memory Cached: 1.9 GB\n",
            "Early stopping at epoch 54\n",
            "Model 1 Best Accuracy: 94.76%\n",
            "\n",
            "============================================================\n",
            "Training Ensemble Model 2/3\n",
            "============================================================\n",
            "Epoch 1/100: Loss = 1.1664 | Test Acc = 81.77% | LR = 0.001000 | Time: September 01, 2025 at 10:27:11 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 1.9 GB\n",
            "Epoch 2/100: Loss = 0.9183 | Test Acc = 84.95% | LR = 0.000999 | Time: September 01, 2025 at 10:28:31 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 1.9 GB\n",
            "Epoch 3/100: Loss = 0.8567 | Test Acc = 88.23% | LR = 0.000998 | Time: September 01, 2025 at 10:29:53 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 1.9 GB\n",
            "Epoch 4/100: Loss = 0.8241 | Test Acc = 88.85% | LR = 0.000996 | Time: September 01, 2025 at 10:31:13 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 1.9 GB\n",
            "Epoch 5/100: Loss = 0.8027 | Test Acc = 90.02% | LR = 0.000994 | Time: September 01, 2025 at 10:32:35 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 1.9 GB\n",
            "Epoch 6/100: Loss = 0.7846 | Test Acc = 89.33% | LR = 0.000991 | Time: September 01, 2025 at 10:33:56 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 1.9 GB\n",
            "Epoch 7/100: Loss = 0.7732 | Test Acc = 89.85% | LR = 0.000988 | Time: September 01, 2025 at 10:35:17 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 1.9 GB\n",
            "Epoch 8/100: Loss = 0.7643 | Test Acc = 90.60% | LR = 0.000984 | Time: September 01, 2025 at 10:36:38 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 1.9 GB\n",
            "Epoch 9/100: Loss = 0.7539 | Test Acc = 91.05% | LR = 0.000980 | Time: September 01, 2025 at 10:37:59 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 1.9 GB\n",
            "Epoch 10/100: Loss = 0.7474 | Test Acc = 91.76% | LR = 0.000976 | Time: September 01, 2025 at 10:39:19 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 1.9 GB\n",
            "Epoch 11/100: Loss = 0.7362 | Test Acc = 91.29% | LR = 0.000970 | Time: September 01, 2025 at 10:40:39 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 1.9 GB\n",
            "Epoch 12/100: Loss = 0.7308 | Test Acc = 91.62% | LR = 0.000965 | Time: September 01, 2025 at 10:41:59 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 1.9 GB\n",
            "Epoch 13/100: Loss = 0.7254 | Test Acc = 91.67% | LR = 0.000959 | Time: September 01, 2025 at 10:43:21 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 1.9 GB\n",
            "Epoch 14/100: Loss = 0.7183 | Test Acc = 92.07% | LR = 0.000952 | Time: September 01, 2025 at 10:44:41 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 1.9 GB\n",
            "Epoch 15/100: Loss = 0.7162 | Test Acc = 92.20% | LR = 0.000946 | Time: September 01, 2025 at 10:46:02 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 1.9 GB\n",
            "Epoch 16/100: Loss = 0.7086 | Test Acc = 92.40% | LR = 0.000938 | Time: September 01, 2025 at 10:47:22 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 1.9 GB\n",
            "Epoch 17/100: Loss = 0.7069 | Test Acc = 92.56% | LR = 0.000930 | Time: September 01, 2025 at 10:48:43 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 1.9 GB\n",
            "Epoch 18/100: Loss = 0.7021 | Test Acc = 92.93% | LR = 0.000922 | Time: September 01, 2025 at 10:50:04 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 1.9 GB\n",
            "Epoch 19/100: Loss = 0.6974 | Test Acc = 92.61% | LR = 0.000914 | Time: September 01, 2025 at 10:51:25 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 1.9 GB\n",
            "Epoch 20/100: Loss = 0.6948 | Test Acc = 92.98% | LR = 0.000905 | Time: September 01, 2025 at 10:52:45 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 1.9 GB\n",
            "Epoch 21/100: Loss = 0.8236 | Test Acc = 92.65% | LR = 0.000895 | Time: September 01, 2025 at 10:54:05 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.1 GB\n",
            "Epoch 22/100: Loss = 0.7460 | Test Acc = 93.67% | LR = 0.000885 | Time: September 01, 2025 at 10:55:25 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.1 GB\n",
            "Epoch 23/100: Loss = 0.7337 | Test Acc = 93.19% | LR = 0.000875 | Time: September 01, 2025 at 10:56:45 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.1 GB\n",
            "Epoch 24/100: Loss = 0.8089 | Test Acc = 93.34% | LR = 0.000865 | Time: September 01, 2025 at 10:58:06 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.1 GB\n",
            "Epoch 25/100: Loss = 0.7850 | Test Acc = 93.30% | LR = 0.000854 | Time: September 01, 2025 at 10:59:28 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.0 GB\n",
            "Epoch 26/100: Loss = 0.7515 | Test Acc = 93.93% | LR = 0.000842 | Time: September 01, 2025 at 11:00:49 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.0 GB\n",
            "Epoch 27/100: Loss = 0.7480 | Test Acc = 93.27% | LR = 0.000831 | Time: September 01, 2025 at 11:02:10 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.0 GB\n",
            "Epoch 28/100: Loss = 0.7692 | Test Acc = 93.32% | LR = 0.000819 | Time: September 01, 2025 at 11:03:31 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.0 GB\n",
            "Epoch 29/100: Loss = 0.7805 | Test Acc = 94.23% | LR = 0.000807 | Time: September 01, 2025 at 11:04:53 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.1 GB\n",
            "Epoch 30/100: Loss = 0.7434 | Test Acc = 93.14% | LR = 0.000794 | Time: September 01, 2025 at 11:06:15 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.0 GB\n",
            "Epoch 31/100: Loss = 0.7627 | Test Acc = 93.90% | LR = 0.000781 | Time: September 01, 2025 at 11:07:36 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.0 GB\n",
            "Epoch 32/100: Loss = 0.7574 | Test Acc = 93.85% | LR = 0.000768 | Time: September 01, 2025 at 11:08:57 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.1 GB\n",
            "Epoch 33/100: Loss = 0.7171 | Test Acc = 93.89% | LR = 0.000755 | Time: September 01, 2025 at 11:10:18 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.1 GB\n",
            "Epoch 34/100: Loss = 0.7512 | Test Acc = 94.14% | LR = 0.000741 | Time: September 01, 2025 at 11:11:39 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.1 GB\n",
            "Epoch 35/100: Loss = 0.7394 | Test Acc = 93.96% | LR = 0.000727 | Time: September 01, 2025 at 11:13:00 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.0 GB\n",
            "Epoch 36/100: Loss = 0.7458 | Test Acc = 93.92% | LR = 0.000713 | Time: September 01, 2025 at 11:14:19 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.1 GB\n",
            "Epoch 37/100: Loss = 0.7457 | Test Acc = 94.22% | LR = 0.000699 | Time: September 01, 2025 at 11:15:40 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.0 GB\n",
            "Epoch 38/100: Loss = 0.7279 | Test Acc = 94.26% | LR = 0.000684 | Time: September 01, 2025 at 11:17:02 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.1 GB\n",
            "Epoch 39/100: Loss = 0.7229 | Test Acc = 94.39% | LR = 0.000670 | Time: September 01, 2025 at 11:18:23 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.0 GB\n",
            "Epoch 40/100: Loss = 0.7137 | Test Acc = 94.11% | LR = 0.000655 | Time: September 01, 2025 at 11:19:44 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.0 GB\n",
            "Epoch 41/100: Loss = 0.7412 | Test Acc = 94.25% | LR = 0.000640 | Time: September 01, 2025 at 11:21:05 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.1 GB\n",
            "Epoch 42/100: Loss = 0.7417 | Test Acc = 94.23% | LR = 0.000625 | Time: September 01, 2025 at 11:22:26 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.1 GB\n",
            "Epoch 43/100: Loss = 0.7234 | Test Acc = 94.42% | LR = 0.000609 | Time: September 01, 2025 at 11:23:46 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.0 GB\n",
            "Epoch 44/100: Loss = 0.7317 | Test Acc = 94.50% | LR = 0.000594 | Time: September 01, 2025 at 11:25:06 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.1 GB\n",
            "Epoch 45/100: Loss = 0.6955 | Test Acc = 94.32% | LR = 0.000579 | Time: September 01, 2025 at 11:26:27 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.1 GB\n",
            "Epoch 46/100: Loss = 0.6902 | Test Acc = 94.31% | LR = 0.000563 | Time: September 01, 2025 at 11:27:48 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.1 GB\n",
            "Epoch 47/100: Loss = 0.6997 | Test Acc = 94.49% | LR = 0.000548 | Time: September 01, 2025 at 11:29:09 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.1 GB\n",
            "Epoch 48/100: Loss = 0.7006 | Test Acc = 94.62% | LR = 0.000532 | Time: September 01, 2025 at 11:30:30 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.0 GB\n",
            "Epoch 49/100: Loss = 0.6804 | Test Acc = 94.30% | LR = 0.000516 | Time: September 01, 2025 at 11:31:51 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.1 GB\n",
            "Epoch 50/100: Loss = 0.6939 | Test Acc = 94.54% | LR = 0.000501 | Time: September 01, 2025 at 11:33:11 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.0 GB\n",
            "Epoch 51/100: Loss = 0.6858 | Test Acc = 94.70% | LR = 0.000485 | Time: September 01, 2025 at 11:34:31 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.1 GB\n",
            "Epoch 52/100: Loss = 0.7389 | Test Acc = 94.40% | LR = 0.000469 | Time: September 01, 2025 at 11:35:51 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.0 GB\n",
            "Epoch 53/100: Loss = 0.7079 | Test Acc = 94.68% | LR = 0.000453 | Time: September 01, 2025 at 11:37:13 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.0 GB\n",
            "Epoch 54/100: Loss = 0.6768 | Test Acc = 94.51% | LR = 0.000438 | Time: September 01, 2025 at 11:38:33 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.0 GB\n",
            "Epoch 55/100: Loss = 0.6613 | Test Acc = 94.91% | LR = 0.000422 | Time: September 01, 2025 at 11:39:54 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.0 GB\n",
            "Epoch 56/100: Loss = 0.6908 | Test Acc = 94.50% | LR = 0.000407 | Time: September 01, 2025 at 11:41:14 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.1 GB\n",
            "Epoch 57/100: Loss = 0.6687 | Test Acc = 94.68% | LR = 0.000392 | Time: September 01, 2025 at 11:42:36 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.0 GB\n",
            "Epoch 58/100: Loss = 0.6706 | Test Acc = 94.73% | LR = 0.000376 | Time: September 01, 2025 at 11:43:58 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.0 GB\n",
            "Epoch 59/100: Loss = 0.6980 | Test Acc = 95.02% | LR = 0.000361 | Time: September 01, 2025 at 11:45:19 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.1 GB\n",
            "Epoch 60/100: Loss = 0.7035 | Test Acc = 94.69% | LR = 0.000346 | Time: September 01, 2025 at 11:46:40 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.1 GB\n",
            "Epoch 61/100: Loss = 0.6595 | Test Acc = 94.92% | LR = 0.000331 | Time: September 01, 2025 at 11:48:01 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.1 GB\n",
            "Epoch 62/100: Loss = 0.6359 | Test Acc = 95.09% | LR = 0.000317 | Time: September 01, 2025 at 11:49:24 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.0 GB\n",
            "Epoch 63/100: Loss = 0.6673 | Test Acc = 94.91% | LR = 0.000302 | Time: September 01, 2025 at 11:50:45 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.0 GB\n",
            "Epoch 64/100: Loss = 0.6860 | Test Acc = 94.95% | LR = 0.000288 | Time: September 01, 2025 at 11:52:07 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.1 GB\n",
            "Epoch 65/100: Loss = 0.6470 | Test Acc = 94.96% | LR = 0.000274 | Time: September 01, 2025 at 11:53:28 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.1 GB\n",
            "Epoch 66/100: Loss = 0.7110 | Test Acc = 94.97% | LR = 0.000260 | Time: September 01, 2025 at 11:54:50 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.0 GB\n",
            "Epoch 67/100: Loss = 0.6649 | Test Acc = 94.99% | LR = 0.000246 | Time: September 01, 2025 at 11:56:12 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.0 GB\n",
            "Epoch 68/100: Loss = 0.6340 | Test Acc = 95.08% | LR = 0.000233 | Time: September 01, 2025 at 11:57:32 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.1 GB\n",
            "Epoch 69/100: Loss = 0.6847 | Test Acc = 95.18% | LR = 0.000220 | Time: September 01, 2025 at 11:58:53 AM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.1 GB\n",
            "Epoch 70/100: Loss = 0.6706 | Test Acc = 95.16% | LR = 0.000207 | Time: September 01, 2025 at 12:00:15 PM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.1 GB\n",
            "Epoch 71/100: Loss = 0.6758 | Test Acc = 95.02% | LR = 0.000194 | Time: September 01, 2025 at 12:01:36 PM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.0 GB\n",
            "Epoch 72/100: Loss = 0.6760 | Test Acc = 94.95% | LR = 0.000182 | Time: September 01, 2025 at 12:02:57 PM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.1 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4075558602.py:319: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-4075558602.py:319: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-4075558602.py:319: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-4075558602.py:319: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-4075558602.py:319: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-4075558602.py:319: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-4075558602.py:319: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-4075558602.py:319: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-4075558602.py:319: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-4075558602.py:377: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-4075558602.py:377: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 73/100: Loss = 0.6376 | Test Acc = 95.15% | LR = 0.000170 | Time: September 01, 2025 at 12:04:18 PM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.1 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4075558602.py:319: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-4075558602.py:319: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-4075558602.py:319: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-4075558602.py:319: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-4075558602.py:319: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-4075558602.py:319: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-4075558602.py:319: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-4075558602.py:319: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-4075558602.py:319: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-4075558602.py:319: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-4075558602.py:319: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-4075558602.py:319: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-4075558602.py:319: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-4075558602.py:319: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-4075558602.py:319: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-4075558602.py:319: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-4075558602.py:319: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-4075558602.py:319: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-4075558602.py:319: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-4075558602.py:377: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 74/100: Loss = 0.6471 | Test Acc = 95.16% | LR = 0.000159 | Time: September 01, 2025 at 12:05:39 PM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.1 GB\n",
            "Epoch 75/100: Loss = 0.6666 | Test Acc = 95.25% | LR = 0.000147 | Time: September 01, 2025 at 12:07:01 PM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.0 GB\n",
            "Epoch 76/100: Loss = 0.6605 | Test Acc = 95.05% | LR = 0.000136 | Time: September 01, 2025 at 12:08:23 PM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.0 GB\n",
            "Epoch 77/100: Loss = 0.6816 | Test Acc = 95.12% | LR = 0.000126 | Time: September 01, 2025 at 12:09:44 PM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.0 GB\n",
            "Epoch 78/100: Loss = 0.6651 | Test Acc = 95.20% | LR = 0.000116 | Time: September 01, 2025 at 12:11:04 PM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.1 GB\n",
            "Epoch 79/100: Loss = 0.6799 | Test Acc = 94.94% | LR = 0.000106 | Time: September 01, 2025 at 12:12:24 PM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.1 GB\n",
            "Epoch 80/100: Loss = 0.6657 | Test Acc = 95.16% | LR = 0.000096 | Time: September 01, 2025 at 12:13:42 PM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.0 GB\n",
            "Epoch 81/100: Loss = 0.6540 | Test Acc = 95.32% | LR = 0.000087 | Time: September 01, 2025 at 12:15:00 PM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.1 GB\n",
            "Epoch 82/100: Loss = 0.6186 | Test Acc = 95.37% | LR = 0.000079 | Time: September 01, 2025 at 12:16:17 PM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.0 GB\n",
            "Epoch 83/100: Loss = 0.6588 | Test Acc = 95.17% | LR = 0.000071 | Time: September 01, 2025 at 12:17:35 PM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.0 GB\n",
            "Epoch 84/100: Loss = 0.6830 | Test Acc = 95.33% | LR = 0.000063 | Time: September 01, 2025 at 12:18:52 PM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.0 GB\n",
            "Epoch 85/100: Loss = 0.6614 | Test Acc = 95.18% | LR = 0.000055 | Time: September 01, 2025 at 12:20:08 PM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.1 GB\n",
            "Epoch 86/100: Loss = 0.6527 | Test Acc = 95.26% | LR = 0.000049 | Time: September 01, 2025 at 12:21:26 PM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.0 GB\n",
            "Epoch 87/100: Loss = 0.6507 | Test Acc = 95.26% | LR = 0.000042 | Time: September 01, 2025 at 12:22:45 PM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.0 GB\n",
            "Epoch 88/100: Loss = 0.6617 | Test Acc = 95.38% | LR = 0.000036 | Time: September 01, 2025 at 12:24:06 PM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.0 GB\n",
            "Epoch 89/100: Loss = 0.6823 | Test Acc = 95.31% | LR = 0.000031 | Time: September 01, 2025 at 12:25:26 PM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.0 GB\n",
            "Epoch 90/100: Loss = 0.6446 | Test Acc = 95.37% | LR = 0.000025 | Time: September 01, 2025 at 12:26:46 PM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.1 GB\n",
            "Epoch 91/100: Loss = 0.7198 | Test Acc = 95.35% | LR = 0.000021 | Time: September 01, 2025 at 12:28:06 PM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.0 GB\n",
            "Epoch 92/100: Loss = 0.6312 | Test Acc = 95.42% | LR = 0.000017 | Time: September 01, 2025 at 12:29:26 PM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.0 GB\n",
            "Epoch 93/100: Loss = 0.6489 | Test Acc = 95.26% | LR = 0.000013 | Time: September 01, 2025 at 12:30:44 PM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.0 GB\n",
            "Epoch 94/100: Loss = 0.6439 | Test Acc = 95.38% | LR = 0.000010 | Time: September 01, 2025 at 12:32:01 PM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.0 GB\n",
            "Epoch 95/100: Loss = 0.6614 | Test Acc = 95.38% | LR = 0.000007 | Time: September 01, 2025 at 12:33:18 PM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.0 GB\n",
            "Epoch 96/100: Loss = 0.6408 | Test Acc = 95.40% | LR = 0.000005 | Time: September 01, 2025 at 12:34:36 PM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.1 GB\n",
            "Epoch 97/100: Loss = 0.6242 | Test Acc = 95.42% | LR = 0.000003 | Time: September 01, 2025 at 12:35:53 PM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.1 GB\n",
            "Epoch 98/100: Loss = 0.6930 | Test Acc = 95.38% | LR = 0.000002 | Time: September 01, 2025 at 12:37:09 PM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.0 GB\n",
            "Epoch 99/100: Loss = 0.6532 | Test Acc = 95.37% | LR = 0.000001 | Time: September 01, 2025 at 12:38:25 PM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.0 GB\n",
            "Epoch 100/100: Loss = 0.6832 | Test Acc = 95.40% | LR = 0.000001 | Time: September 01, 2025 at 12:39:42 PM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.0 GB\n",
            "Model 2 Best Accuracy: 95.42%\n",
            "\n",
            "============================================================\n",
            "Training Ensemble Model 3/3\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4075558602.py:301: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Mixed precision training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100: Loss = 1.1837 | Test Acc = 79.78% | LR = 0.001100 | Time: September 01, 2025 at 12:40:57 PM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.3 GB\n",
            "Epoch 2/100: Loss = 0.9256 | Test Acc = 86.15% | LR = 0.001099 | Time: September 01, 2025 at 12:42:13 PM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.3 GB\n",
            "Epoch 3/100: Loss = 0.8689 | Test Acc = 87.52% | LR = 0.001098 | Time: September 01, 2025 at 12:43:29 PM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.3 GB\n",
            "Epoch 4/100: Loss = 0.8316 | Test Acc = 87.92% | LR = 0.001096 | Time: September 01, 2025 at 12:44:46 PM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.3 GB\n",
            "Epoch 5/100: Loss = 0.8119 | Test Acc = 89.27% | LR = 0.001093 | Time: September 01, 2025 at 12:46:01 PM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.3 GB\n",
            "Epoch 6/100: Loss = 0.7983 | Test Acc = 90.24% | LR = 0.001090 | Time: September 01, 2025 at 12:47:19 PM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.3 GB\n",
            "Epoch 7/100: Loss = 0.7806 | Test Acc = 90.34% | LR = 0.001087 | Time: September 01, 2025 at 12:48:37 PM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.3 GB\n",
            "Epoch 8/100: Loss = 0.7667 | Test Acc = 90.04% | LR = 0.001083 | Time: September 01, 2025 at 12:49:55 PM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.3 GB\n",
            "Epoch 9/100: Loss = 0.7620 | Test Acc = 90.14% | LR = 0.001078 | Time: September 01, 2025 at 12:51:12 PM\n",
            "GPU Memory Used: 0.3 GB\n",
            "GPU Memory Cached: 2.3 GB\n"
          ]
        }
      ]
    }
  ]
}